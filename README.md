# LLM Internals

This repository aims to explore and understand the internal workings of Large Language Models (LLMs) through practical examples and explanations.

## Contents

### 1. [Structured Outputs](./structured_outputs/)
Explores how LLMs can be constrained to generate outputs in specific formats like JSON or tables. Covers:
- How LLMs process and generate text using tokenization
- Techniques for constraining LLM outputs to follow specific patterns
- Implementation of format-specific state machines for validation

## Purpose

The main goal of this repository is to provide clear, hands-on examples that demonstrate how LLMs work internally. Rather than treating them as black boxes, we dive into their mechanics to understand:

- How they process and generate text
- Ways to control and constrain their outputs
- Implementation details of various LLM features

## Getting Started

Each folder contains its own README with specific details about the concepts covered and how to run the examples.

## Contributing

Feel free to open issues or submit pull requests if you have suggestions for improvements or additional topics to explore. 